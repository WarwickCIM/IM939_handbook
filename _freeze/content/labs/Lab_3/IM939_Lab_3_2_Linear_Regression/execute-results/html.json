{
  "hash": "d286d3c4b94663984114f55bbd5a2923",
  "result": {
    "markdown": "# Lab: Regressions\n\nIn this lab, inspired by @igual_regression_2017, we will introduce simple linear regression in Python to try to answer the question: _Has there been a decrease in the amount of ice in the last years?_ To do so, we are going to use `Scikit Learn`, a machine learning library, and the [Sea Ice Index Daily and Monthly Image Viewer](https://nsidc.org/data/seaice_index) dataset from the National Snow and Ice Data Center.\n\n\n## Key concepts' refresher\n\nLet's refresh some theoretical concepts to understand what we are going to do.\n\n### Simple and Multiple Linear Regression\n\nIn the **linear model** the response $\\textbf{y}$ depends linearly from the covariates $\\textbf{x}_i$.\n\nIn the **simple** linear regression, with a single variable, we described the relationship between the predictor and the response with a straight line. The general linear model:\n$$ \\textbf{y}  =  a_0+ a_1 \\textbf{x}_1 $$\n\nThe parameter $a_0$ is called the *constant* term or the *intercept*.\n\nIn the case of **multiple** linear regression we extend this idea by fitting a m-dimensional hyperplane to our m predictors.\n\n$$ \\textbf{y}  =  a_1 \\textbf{x}_1  + \\dots + a_m \\textbf{x}_{m} $$\n\nThe $a_i$ are termed the *parameters* of the model or the coefficients.\n\n### Ordinary Least Squares\n\nOrdinary Least Squares (OLS) is the simplest and most common **estimator** in which the coefficients $a$'s \nof the simple linear regression: $\\textbf{y} = a_0+a_1 \\textbf{x}$, \nare chosen to minimize the **square of the distance between the predicted values and the actual values**. \n\n$$ ||a_0 + a_1 \\textbf{x} -  \\textbf{y} ||^2_2 = \\sum_{j=1}^n (a_0+a_1 x_{j} -  y_j )^2,$$ \n\nThis expression is often called **sum of squared errors of prediction (SSE)**.\n\n## Case study: Climate Change and Sea Ice Extent\n\nRemember, we are trying to answer the following research question: _Has there been a decrease in the amount of ice in the last years?_\n\n### Data assessment\n\nFirst, let's load the `SeaIce.txt` dataset that is already in the `data` folder[^seaice]. It is a text file, but unlike `csv` files, where columns are separated by commas (`,`), it is a `Tab` separated file, where each `Tab` delimites the following columns:\n\n- `Year`:\t4-digit year\n- `mo`:\t1- or 2-digit month\n- `data_type`:\tInput data set (Goddard/NRTSI-G)\n- `region`:\tHemisphere that this data covers (N: Northern; S: Southern)\n- `extent`:\tSea ice extent in millions of square km\n- `area`:\tSea ice area in millions of square km\n\nOnce we upload the data, we can create a `DataFrame` using Pandas using the well known `read_csv()` function, but in this case, because columns are not separated by commas as expected, but Tabs, we will need to use the `delim_whitespace=True` argument. \n\n[^seaice]: The original dataset was downloaded from <https://nsidc.org/data/g02135/versions/3>, which provides useful metadata information, as well as API services.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nice = pd.read_csv('data/raw/SeaIce.txt', delim_whitespace=True)\n\nice.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 424 entries, 0 to 423\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   year       424 non-null    int64  \n 1   mo         424 non-null    int64  \n 2   data_type  424 non-null    object \n 3   region     424 non-null    object \n 4   extent     424 non-null    float64\n 5   area       424 non-null    float64\ndtypes: float64(2), int64(2), object(2)\nmemory usage: 20.0+ KB\n```\n:::\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nice.head() \n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>mo</th>\n      <th>data_type</th>\n      <th>region</th>\n      <th>extent</th>\n      <th>area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>Goddard</td>\n      <td>N</td>\n      <td>15.54</td>\n      <td>12.33</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1980</td>\n      <td>1</td>\n      <td>Goddard</td>\n      <td>N</td>\n      <td>14.96</td>\n      <td>11.85</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1981</td>\n      <td>1</td>\n      <td>Goddard</td>\n      <td>N</td>\n      <td>15.03</td>\n      <td>11.82</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1982</td>\n      <td>1</td>\n      <td>Goddard</td>\n      <td>N</td>\n      <td>15.26</td>\n      <td>12.11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1983</td>\n      <td>1</td>\n      <td>Goddard</td>\n      <td>N</td>\n      <td>15.10</td>\n      <td>11.92</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAnd we can get some summary statistics from the numerical attributes:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nice.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>mo</th>\n      <th>extent</th>\n      <th>area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>424.000000</td>\n      <td>424.000000</td>\n      <td>424.000000</td>\n      <td>424.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1996.000000</td>\n      <td>6.500000</td>\n      <td>-35.443066</td>\n      <td>-37.921108</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>10.214716</td>\n      <td>3.474323</td>\n      <td>686.736905</td>\n      <td>686.566381</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1978.000000</td>\n      <td>1.000000</td>\n      <td>-9999.000000</td>\n      <td>-9999.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1987.000000</td>\n      <td>3.000000</td>\n      <td>9.272500</td>\n      <td>6.347500</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1996.000000</td>\n      <td>6.500000</td>\n      <td>12.385000</td>\n      <td>9.895000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2005.000000</td>\n      <td>10.000000</td>\n      <td>14.540000</td>\n      <td>12.222500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2014.000000</td>\n      <td>12.000000</td>\n      <td>16.450000</td>\n      <td>13.840000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: callout-warning\n\nDid we receive a negative mean for `extent` and `area`? What this could possibly mean? Probably, inspecting those attributes visually could give us a clue.\n\n:::\n\n### Data visualisation to explore data\n\nWe will use Seaborn's `lmplot()` function to explore linear relationship of different forms, e.g. relationship between the `month` of the `year` (variable) and `extent` (responses):\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Visualize the data\nplt.scatter(ice.mo, ice.extent, color = 'red')\nplt.xlabel('Year')\nplt.ylabel('Extent')\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nText(0, 0.5, 'Extent')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_3_2_Linear_Regression_files/figure-html/cell-6-output-2.png){width=621 height=429}\n:::\n:::\n\n\n::: callout-warning\n\nWe detect some outlier or missing data. This might have to do with those negative mean values that we detected previously.\n\n:::\n\nWe can use numpy's function [`np.unique()`](https://numpy.org/doc/stable/reference/generated/numpy.unique.html) to find the unique elements of an array.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nprint ('Different values in data_type field:', np.unique(ice.data_type.values))   # there is a -9999 value!\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDifferent values in data_type field: ['-9999' 'Goddard' 'NRTSI-G']\n```\n:::\n:::\n\n\nLet's see what type of data we have, other than the ones printed above \n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nice[(ice.data_type != 'Goddard') & (ice.data_type != 'NRTSI-G')]\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>mo</th>\n      <th>data_type</th>\n      <th>region</th>\n      <th>extent</th>\n      <th>area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>1988</td>\n      <td>1</td>\n      <td>-9999</td>\n      <td>N</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>1987</td>\n      <td>12</td>\n      <td>-9999</td>\n      <td>N</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Data cleaning\n\nWe checked all the values and notice `-9999` values in data_type field which should contain `Goddard` or `NRTSI-G` (some type of input dataset).\n\nIn this case, we will clean them by creating a _copy_ of the original dataframe that does not include these instances.\n\n::: callout-important\n\n### Dataframe copies vs instances\n\nUnless we do not explicitly create a copy of a dataframe, when subsetting a dataframes we are actually creating instances. Whereas copies are totally independent objects from the original one, instances are reduced \"views\" from the original, meaning that if we change a value on the instance, we are also changing the value on the original data frame, which may not be what we wanted to do. \n\nAn explanation of how (and why) do we need to create copies can be found here: <https://www.statology.org/pandas-copy-dataframe/>\n\n:::\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# We can easily clean the data now:\nice2 = ice[ice.data_type != '-9999'].copy()\n\nprint ('shape:', ice2.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (422, 6)\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# And repeat the plot, without the outliers\nplt.scatter(ice2.mo, ice2.extent, color = 'red')\nplt.xlabel('Month')\nplt.ylabel('Extent')\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nText(0, 0.5, 'Extent')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_3_2_Linear_Regression_files/figure-html/cell-10-output-2.png){width=585 height=429}\n:::\n:::\n\n\n::: {.cell .column-page-right execution_count=10}\n``` {.python .cell-code}\nsns.relplot(ice2, x = \"mo\", y = \"extent\", aspect = 2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/u2071219/anaconda3/envs/IM939/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(vector):\n/Users/u2071219/anaconda3/envs/IM939/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(vector):\n/Users/u2071219/anaconda3/envs/IM939/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(vector):\n/Users/u2071219/anaconda3/envs/IM939/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(vector):\n/Users/u2071219/anaconda3/envs/IM939/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(vector):\n/Users/u2071219/anaconda3/envs/IM939/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(vector):\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_3_2_Linear_Regression_files/figure-html/cell-11-output-2.png){width=949 height=468}\n:::\n:::\n\n\n## Regression model fit\n\nNow that we have a clean dataset, we can use Seaborn's [`lmplot()`](https://seaborn.pydata.org/generated/seaborn.lmplot.html) function comparing month vs extent. \n\nThe `lmplot()` function from the Seaborn module is intended for exploring linear relationships of different forms in multidimensional datesets. Input data must be in a Pandas DataFrame. To plot them, we provide the predictor (`mo`) and response (`extent`) variable names along with the dataset (`ice2`).\n\n::: {.cell .column-page-right execution_count=11}\n``` {.python .cell-code}\nsns.lmplot(ice2, x = \"mo\", y = \"extent\", aspect=2);\n\n# Uncomment below to save the resulting plot.\n#plt.savefig(\"figs/CleanedByMonth.png\", dpi = 300, bbox_inches = 'tight')\n```\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_3_2_Linear_Regression_files/figure-html/cell-12-output-1.png){width=949 height=468}\n:::\n:::\n\n\nAbove you can see ice extent data by month.\nYou can see a monthly fluctuation of the sea ice extent, as would be expected for the different seasons of the year. In order to run regression, and avoid this fluctuation we can normalize data. This will let us see the evolution of the extent over the years.\n\n### Normalization\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# Compute the mean for each month.\nmonth_means = ice2.groupby('mo').extent.mean()\n\n# Compute the variance for each month.\nmonth_variances = ice2.groupby('mo').extent.var()\n\n# Show the values:\nprint('Means:', month_means)\nprint('\\n') # Add a new line between the two prints, so they are easily distinguishible.\nprint ('Variances:',month_variances)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMeans: mo\n1     14.479429\n2     15.298889\n3     15.491714\n4     14.766000\n5     13.396000\n6     11.860000\n7      9.601143\n8      7.122286\n9      6.404857\n10     8.809143\n11    10.964722\n12    13.059429\nName: extent, dtype: float64\n\n\nVariances: mo\n1     0.304906\n2     0.295804\n3     0.237209\n4     0.215378\n5     0.189901\n6     0.247918\n7     0.679175\n8     0.824577\n9     1.143902\n10    0.630361\n11    0.412511\n12    0.284870\nName: extent, dtype: float64\n```\n:::\n:::\n\n\nTo capture variation per month, we can compute mean for the i-th interval of time (using 1979-2014) and subtract it from the set of extent values for that month . This can be converted to a relative pecentage difference by dividing it by the total avareage (1979-2014) and multiplying by 100.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# Data normalization\nfor i in range(12):\n    ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n    \nsns.lmplot(ice2 , x = \"mo\", y = \"extent\", height = 5.2, aspect = 2);\n#plt.savefig(\"figs/IceExtentNormalizedByMonth.png\", dpi = 300, bbox_inches = 'tight')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_75501/2141240604.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ice2.extent[ice2.mo == i+1] = 100*(ice2.extent[ice2.mo == i+1] - month_means[i+1])/month_means.mean()\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_3_2_Linear_Regression_files/figure-html/cell-14-output-2.png){width=988 height=488}\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nprint ('mean:', ice2.extent.mean())\nprint ('var:', ice2.extent.var())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nmean: -7.745252569896827e-16\nvar: 31.983239774968798\n```\n:::\n:::\n\n\nLet us consider the entire year\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nsns.lmplot(ice2, x = \"year\", y = \"extent\", height = 5.2, aspect = 2);\n#plt.savefig(\"figs/IceExtentAllMonthsByYearlmplot.png\", dpi = 300, bbox_inches = 'tight')\n```\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_3_2_Linear_Regression_files/figure-html/cell-16-output-1.png){width=988 height=488}\n:::\n:::\n\n\n### Pearson's correlation\n\nLet's calculate Pearson's correlation coefficient and the p-value for testing non-correlation.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nimport scipy.stats\nscipy.stats.pearsonr(ice2.year.values, ice2.extent.values)\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\nPearsonRResult(statistic=-0.8183500709897178, pvalue=4.4492318168687107e-103)\n```\n:::\n:::\n\n\n### Simple OLS\n\nWe can also compute the trend as a simple linear regression (OLS) and quantitatively evaluate it.\n\nFor that we use using **Scikit-learn**, library that provides a variety of both supervised and unsupervised machine learning techniques.\nScikit-learn provides an object-oriented interface centered around the concept of an Estimator. \nThe <code>Estimator.fit</code> method sets the state of the estimator based on the training data. Usually, the data is comprised of a two-dimensional numpy array $X$ of shape <code>(n_samples, n_predictors)</code> that holds the so-called feature matrix and a one-dimensional numpy array $\\textbf{y}$ that holds the responses. Some estimators allow the user to control the fitting behavior. \nFor example, the <code>sklearn.linear_model.LinearRegression</code> estimator allows the user to specify whether or not to fit an intercept term. This is done by setting the corresponding constructor arguments of the estimator object.\nDuring the fitting process, the state of the estimator is stored in instance attributes that have a trailing underscore (`_`). For example, the coefficients of a LinearRegression estimator are stored in the attribute `coef_`.\n\nEstimators that can generate predictions provide a `Estimator.predict` method. \nIn the case of regression, `Estimator.predict` will return the predicted regression values, $\\hat{\\textbf{y}}$. \n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\n\nest = LinearRegression(fit_intercept = True)\n\nx = ice2[['year']]\ny = ice2[['extent']]\n\nest.fit(x, y)\n\nprint(\"Coefficients:\", est.coef_)\nprint (\"Intercept:\", est.intercept_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCoefficients: [[-0.45275459]]\nIntercept: [903.71640207]\n```\n:::\n:::\n\n\nWe can evaluate the model fitting by computing the mean squared error ($MSE$) and the coefficient of determination ($R^2$) of the model.\nThe coefficient $R^2$ is defined as $(1 - \\textbf{u}/\\textbf{v})$, where $\\textbf{u}$ is the residual sum of squares $\\sum (\\textbf{y} - \\hat{\\textbf{y}})^2$ and $\\textbf{v}$ is the regression sum of squares $\\sum (\\textbf{y} - \\bar{\\textbf{y}})^2$, where $\\bar{\\textbf{y}}$ is the mean.\nThe best possible score for $R^2$ is 1.0: lower values are worse.\nThese measures can provide a quantitative answer to the question we are facing: Is there a negative trend in the evolution of sea ice extent over recent years?\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nfrom sklearn import metrics\n\n# Analysis for all months together.\nx = ice2[['year']]\ny = ice2[['extent']]\nmodel = LinearRegression()\nmodel.fit(x, y)\ny_hat = model.predict(x)\nplt.plot(x, y,'o', alpha = 0.5)\nplt.plot(x, y_hat, 'r', alpha = 0.5)\nplt.xlabel('year')\nplt.ylabel('extent (All months)')\nprint (\"MSE:\", metrics.mean_squared_error(y_hat, y))\nprint (\"R^2:\", metrics.r2_score(y_hat, y))\nprint (\"var:\", y.var())\n#plt.savefig(\"figs/IceExtentLinearRegressionAllMonthsByYearPrediction.png\", dpi = 300, bbox_inches = 'tight')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMSE: 10.539131639803488\nR^2: 0.5067870382100226\nvar: extent    31.98324\ndtype: float64\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_3_2_Linear_Regression_files/figure-html/cell-19-output-2.png){width=602 height=429}\n:::\n:::\n\n\nWe can conclude that the data show a long-term negative trend in recent years.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n# Analysis for a particular month.\n#For January\njan = ice2[ice2.mo == 1];\n\nx = jan[['year']]\ny = jan[['extent']]\n\nmodel = LinearRegression()\nmodel.fit(x, y)\n\ny_hat = model.predict(x)\n\nplt.figure()\nplt.plot(x, y,'-o', alpha = 0.5)\nplt.plot(x, y_hat, 'r', alpha = 0.5)\nplt.xlabel('year')\nplt.ylabel('extent (January)')\n\nprint (\"MSE:\", metrics.mean_squared_error(y_hat, y))\nprint (\"R^2:\", metrics.r2_score(y_hat, y))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMSE: 3.8395160752867565\nR^2: 0.7810636041396216\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_3_2_Linear_Regression_files/figure-html/cell-20-output-2.png){width=607 height=429}\n:::\n:::\n\n\nWe can also estimate the extent value for 2025. For that we use the function predict of the model.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nX = np.array(2025) \ny_hat = model.predict(X.reshape(-1, 1))\nj = 1 # January\n# Original value (before normalization)\ny_hat = (y_hat*month_means.mean()/100) + month_means[j]\nprint (\"Prediction of extent for January 2025 (in millions of square km):\", y_hat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPrediction of extent for January 2025 (in millions of square km): [[13.14449923]]\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/u2071219/anaconda3/envs/IM939/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n  warnings.warn(\n```\n:::\n:::\n\n\nPrediction of extent for January 2025 (in millions of square km): 13.14449923\n\n## More information\n\nYou can find more information about using `scikit` for Linear regression here: <https://www.tutorialspoint.com/scikit_learn/scikit_learn_linear_regression.htm>\n\n",
    "supporting": [
      "IM939_Lab_3_2_Linear_Regression_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}