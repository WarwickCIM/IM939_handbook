{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IM939 - Lab 3 - Regression Exercise ANSWERS\n",
    "\n",
    "Here you can find anwsers to the TEAM task from Week 03. Did you end up building the same linear regression model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use Scikit Learn library: https://www.tutorialspoint.com/scikit_learn/scikit_learn_linear_regression.htm\n",
    "\n",
    "\n",
    "## Wine Dataset\n",
    "\n",
    "The dataset for this task is the wine dataset. More information here: https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What would be your research question? What do you want to learn?_\n",
    "\n",
    "(The wine dataset allows multiple different regression models. It is even prompted in the description of the dataset I linked above: \"Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods.\" I will show one example here. Feel free to discuss your models in \"Q&A coding\" channel on Teams and share it with you colleagues!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My **research question** is: What determines the wine density?  \n",
    "Therefore my dependent variable will be \"density\". What will be the predictors? I could do some quick research, look for some resources in order to create some hypotheses. This would be something like theory-based approach. \n",
    "What if we didn't do any research to help us build any hypotheses about wine (maybe besisdes from some tasting ;)? That's when we need to run a lot of checks and explore data more, looking for insights or patterns. I can just try all of them, or those that make more sense to me, given that they are only 11. This would be a data-driven approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_excel('winequality-red_v2.xlsx')\n",
    "\n",
    "#You might need to use encoding, then the code will look like:\n",
    "# wine = pd.read_excel('winequality-red_v2.xlsx', encoding='UTF-8')\n",
    "\n",
    "type(wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "### Univariate analysis\n",
    "It is time to check the data, their distribution and central tendencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape:', wine.shape)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the quality column above. It is the only column where you don't see decimals. This may suggest it is not a continuous variable. Read the dataset description: https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "It is already suggested there: \"Output variable (based on sensory data): 12 - quality (score between 0 and 10)\". It is the only variable that is not based on physicochemical tests. It was probably a subjective score defined by wine tasters.\n",
    "\n",
    "If you build a regression model to explain wine quality, your research question should sound: \"What determines perception of the quality of wine??\" to be very precise. Do you know why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do mean results tell us? Here they give a quick overview, suggesting that variables are in different ranges. We know that quality variable is a score between 0 and 10. Let's see what are the minimum and maximum values for the physicochemical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see clearly what we already suspected: the variables have different value ranges i.e. are on different scales. \n",
    "Also, it looks like that not the full quality scale is actually used in the data. The lowest score is 3, the highest 8. The total_sulfur_dioxide has values of even 289, whereas citric_acid is maximum 1. The latter may suggest it is ratio or %. But alcohol for sure is expressed in %, but the max value is only 14.9. \n",
    "What shall we do then...? Looks like standarization is needed. Or normalization?\n",
    "\n",
    "For that we will use a short code written by de Filippi. Check also his explanation of normalization and standarisation.\n",
    "https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is code for normalization\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# Normalize variable of alcohol\n",
    "x_array = np.array(wine['alcohol'])\n",
    "normalized_X = preprocessing.normalize([x_array])\n",
    "\n",
    "#if you are going to use this normalized variable, or any other, remember to put its new name \"normalized_X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is code for standarization  \n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "#Get column names first\n",
    "names = wine.columns\n",
    "#Create the Scaler object\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#Fit your data on the scaler object\n",
    "st_wine = scaler.fit_transform(wine)\n",
    "st_wine = pd.DataFrame(st_wine, columns=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run some histograms below to check the distribution *after* the standarization. That's why we use the new data frame called \"st_wine\". Compare with \"wine\" only dataset and see what changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=st_wine, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_wine.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that some of variables are skewed. The histogram for 'wine quality' confirms it is not a continuos variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate analyis \n",
    "\n",
    "Let's explore a bit more towards building a regression model. First, let's check the variables using plots. \n",
    "\n",
    "We can use a pairplot to have a general overview on all variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(st_wine, height=1.5) #careful, this may take a while due to the number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the number of variables, the pairplot is not easy to read though. \n",
    "We can either pick some variables or just plot one by one for the most relevant variables.\n",
    "\n",
    "If we go for the second option we can use  lmplot() functions from Seaborn. This will help to explore linear relationship. Input data must be in a Pandas DataFrame. \n",
    "\n",
    "To plot them, we provide the potential predictor variable and response variable names along with the dataset.\n",
    "\n",
    "Let's start with alcohol first as a potential predictor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = st_wine.density\n",
    "y = st_wine.alcohol\n",
    "plt.scatter(x, y, color = 'purple')\n",
    "plt.xlabel('Wine density')\n",
    "plt.ylabel('Alcohol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would chart look like if you were to run on original variables, before standarization? Try it - just change \"st_wine\" to \"wine_\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "You can calculate a Pearson correlation coefficient and the p-value for testing non-correlation.\n",
    "Instead of running it one by one for every pair of variables, like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "#scipy.stats.pearsonr(st_wine.quality.values, st_wine.alcohol.values)\n",
    "#scipy.stats.pearsonr(st_wine.quality.values, st_wine.residual_sugar.values)\n",
    "scipy.stats.pearsonr(st_wine.alcohol.values, st_wine.density.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or you can build a correlation matrix of all variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "#instead of running it one by one for every pair of variables, like:\n",
    "#scipy.stats.pearsonr(st_wine.quality.values, st_wine.alcohol.values) \n",
    "\n",
    "corrMatrix = st_wine.corr().round(2)\n",
    "print (corrMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard to read a bit? Let's build a heatmap! I used the code from here: https://datatofish.com/correlation-matrix-pandas/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corrMatrix = st_wine.corr().round(1)  #I added here \".round(1)\" so that's easier to read given number of variables\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you identify some variables that are closely related? \n",
    "Try to make inferences about:\n",
    "#1. pairs of variables \n",
    "#2. also about subsets of variables that might be related to one another. \n",
    "\n",
    "In models we build sometimes indicators that are *proxies* of some phenomena, e.g. poverty can be created from Illiteracy level, access to health and nutrition. Can you think of some indicators here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Regression\n",
    "\n",
    "The heatmap helps choosing good predictors. Of course, we could go further by doing some more research, but let's keep it simple here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "We will be using Scikit-learn to build a simple linear regression (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "est = LinearRegression(fit_intercept = True)\n",
    "x = wine[['alcohol']]\n",
    "y = wine[['density']]\n",
    "\n",
    "est.fit(x, y)\n",
    "\n",
    "print(\"Coefficients:\", est.coef_)\n",
    "print (\"Intercept:\", est.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the model's mean squared error ($MSE$) and the coefficient of determination ($R^2$) ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "y_hat = model.predict(x)\n",
    "plt.plot(x, y,'o', alpha = 0.5)\n",
    "plt.plot(x, y_hat, 'r', alpha = 0.5)\n",
    "plt.xlabel('alcohol')\n",
    "plt.ylabel('density')\n",
    "print (\"MSE:\", metrics.mean_squared_error(y, y_hat))\n",
    "print (\"R^2:\", metrics.r2_score(y, y_hat))\n",
    "print (\"var:\", y.var())\n",
    "plt.savefig(\"wine.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the conclusion? \n",
    "The regression line shows a linear relationship. We can see a negative trend. The more alcohol in the wine, the less density wine has.  \n",
    "\n",
    "We aim for **MSE** to be low, the closer to 0 the better. It's much lower than in our icesea example.\n",
    "\n",
    "And *$R^2$* is a bit low (0.24), given that it can have values between 0 and 1. It indicates what portion of the variance of wine density was explained - around 24%. That's why we can try adding more predictors to see if they help explain the density of wine. \n",
    "Also, in single linear regression you can use a square of correlation coefficient for variance explained: 0.49*0.49 (see correlation result above) equals 0.24 ($R^2$).\n",
    "\n",
    "The **Intercept** tells us (the constant) is the expected mean value of Y when all X=0. In our case we have only one x - alcohol. \n",
    "How  do we interpret it?\n",
    "\n",
    "*standarized values*: when there is no alcohol in wine, the density will be lower by -3.4 standard deviations.\n",
    "\n",
    "*not standarized values*: when there is no alcohol in wine, the density equals 1.\n",
    "\n",
    "**Coefficient** equals -0.496 (based on standarized values), i.e. if value of alcohol increases by 1 standard deviation, then density will decrease by 0.49 of its standard deviation. In non-standarized values it equals -0.0008, so if alcohol is increased by 1%, the density will decrease by... Exactly, how much density is a lot...? We don't know that. It's harder to interpret than e.g. 1 cm or 1 year. That's where standarized values come handy.\n",
    "\n",
    "\n",
    "## Multiple linear regression\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try adding more predictors to see if they help explain the density of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "est = LinearRegression(fit_intercept = True) \n",
    "x = st_wine[['alcohol','fixed_acidity']]\n",
    "y = st_wine[['density']]\n",
    "\n",
    "est.fit(x, y)\n",
    "\n",
    "print(\"Coefficients:\", est.coef_)\n",
    "print (\"Intercept:\", est.intercept_)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "y_hat = model.predict(x)\n",
    "print (\"MSE:\", metrics.mean_squared_error(y, y_hat))\n",
    "print (\"R^2:\", metrics.r2_score(y, y_hat))\n",
    "print (\"var:\", y.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that by adding acidity our R2 got much better. Now we continue the fun by trying to find even better model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
