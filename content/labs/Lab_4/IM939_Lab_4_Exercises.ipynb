{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Wine dataset\n",
    "\n",
    "As with previous exercises, fill in the question marks with the correct code.\n",
    "\n",
    "Last week you were introduced to the [wine dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality). We have 10 input variables and 1 output variables.\n",
    "\n",
    "Input variables (based on physicochemical tests):\n",
    "\n",
    "1. fixed acidity\n",
    "2. volatile acidity\n",
    "3. citric acid\n",
    "4. residual sugar\n",
    "5. chlorides\n",
    "6. free sulfur dioxide\n",
    "7. total sulfur dioxide\n",
    "8. density\n",
    "9. pH\n",
    "10. sulphates\n",
    "11. alcohol\n",
    "\n",
    "Output variable (based on sensory data):\n",
    "\n",
    "12. quality (score between 0 and 10)\n",
    "\n",
    "I suggest we look at two broad questions with this dataset:\n",
    "\n",
    "1. Will dimension reduction reveal variable groupings? Think back to how we interpreted the loadings in the crime dataset.\n",
    "2. What does clustering the wines well us?\n",
    "\n",
    "## Load data and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sn?\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PC?\n",
    "from sklearn.decomposition import S????ePCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "df = pd.read_excel('data/winequality-red_v2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "df.h??d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "# May take a while depending on your computer\n",
    "# feel free not to run this\n",
    "sns.pair????(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 2\n",
    " \n",
    "pca = PCA(n_??????????=n_components)\n",
    "df_pca = pca.fit(df?iloc[:, 0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "df_pca_vals = df_pca.???_transform(df.iloc[:, 0:11])\n",
    "df['c1'] = [item[0] for item in df_pca_????]\n",
    "df['c2'] = [item[1] for item in df_pca_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "sns.scatterplot(data = df, x = ?, y = ?, hue = 'quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "print(df.columns)\n",
    "df_pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about other dimension reduction methods?\n",
    "\n",
    "## SparcePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "s_pca = SparsePCA(n_components=n_components)\n",
    "df_s_pca = s_pca.fit(df.????[:, 0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "df_s_pca_vals = s_pca.fit_?????????(df.iloc[:, 0:11])\n",
    "df['c1 spca'] = [item[0] for item in df_s_pca_vals]\n",
    "df['c2 spca'] = [item[1] for item in df_s_pca_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "sns.scatterplot(data = df, x = 'c1 spca', y = 'c2 spca', hue = 'quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "tsne_model = TSNE(n_components=n_components)\n",
    "df_tsne = tsne_model.fit(df.iloc[:, 0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "df_tsne_vals = tsne_model.fit_transform(df.iloc[:, 0:11])\n",
    "df['c1 tsne'] = [item[0] for item in ??_tsne_vals]\n",
    "df['c2 tsne'] = [item[1] for item in df_tsne_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "# This plot does not look right\n",
    "# I am not sure why.\n",
    "sns.scatterplot(data = ??, x = 'c1 tsne', y = 'c1 tsne', hue = 'quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks concerning - there is a straight line. It looks like something in the data has caused the model to have issues.\n",
    "\n",
    "Does normalising the data sort out the issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "col_names = df.columns\n",
    "scaled_df =  pd.DataFrame(MinMaxScaler().fit_transform(df))\n",
    "scaled_df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "tsne_model = TSNE(n_components=n_components)\n",
    "\n",
    "scaled_df_tsne = tsne_model.fit(scaled_df.iloc[:, 0:11])\n",
    "scaled_df_tsne_vals = tsne_model.fit_transform(df.iloc[:, 0:11])\n",
    "\n",
    "scaled_df['c1 tsne'] = [item[0] for item in scaled_df_tsne_vals]\n",
    "scaled_df['c2 tsne'] = [item[1] for item in scaled_df_tsne_vals]\n",
    "\n",
    "sns.scatterplot(data = scaled_df, x = 'c1 tsne', y = 'c1 tsne', hue = 'quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising the data makes no difference. It could be the model is getting stuck somehow. You could check the various attributes of the tsne fit object (tsne_model.fit), try using only a few columns and search google a lot - this could be a problem other have encountered.\n",
    "\n",
    "For now, we will use PCA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "data = {'columns' : df.iloc[:, 0:11].columns,\n",
    "        'component 1' : df_pca.components_[0],\n",
    "        'component 2' : df_pca.components_[1]}\n",
    "\n",
    "\n",
    "loadings = pd.?????????(data)\n",
    "loadings_sorted = loadings.sort_values(by=['component 1'], ascending=False)\n",
    "loadings_sorted.iloc[1:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "loadings_sorted = loadings.sort_values(by=['component 2'], ascending=False)\n",
    "loadings_sorted.iloc[1:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "ks = range(1, 10)\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    # Create a KMeans instance with k clusters: model\n",
    "    ????? = KMeans(n_clusters=k)\n",
    "    \n",
    "    # Fit model to samples\n",
    "    model.fit(df[['c1', 'c2']])\n",
    "    \n",
    "    # Append the inertia to the list of inertias\n",
    "    inertias.append(model.inertia_)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ks, inertias, '-o', color='black')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "k_means_3 = KMeans(n_clusters = 3, init = 'random')\n",
    "k_means_3.fit(df[['c1', 'c2']])\n",
    "df['Three clusters'] = pd.Series(k_means_3.???????(df[['c1', 'c2']].values), index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "sns.scatterplot(data = df, x = 'c1', y = 'c2', hue = 'Three clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider:\n",
    "\n",
    "* Is that userful? \n",
    "* What might it mean?\n",
    "\n",
    "Outside of this session you could try normalising the data (centering around the mean), clustering the raw data (and not the projections from PCA), trying to get tSNE working or using different numbers of components."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
