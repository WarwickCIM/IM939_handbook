{
  "hash": "961f41bc79e9a47bcdc649dbef583ef2",
  "result": {
    "markdown": "# Lab: Investigating multidimensional scaling\n\nHere we look at some London Borough data.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\ndf = pd.read_excel('data/london-borough-profilesV3.xlsx', engine = 'openpyxl')\ndf.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nIndex(['Code', 'Area/INDICATOR', 'Inner/ Outer London',\n       'GLA Population Estimate 2013', 'GLA Household Estimate 2013',\n       'Inland Area (Hectares)', 'Population density (per hectare) 2013',\n       'Average Age, 2013', 'Proportion of population aged 0-15, 2013',\n       'Proportion of population of working-age, 2013',\n       'Proportion of population aged 65 and over, 2013',\n       '% of resident population born abroad (2013)',\n       'Largest migrant population by country of birth (2013)',\n       '% of largest migrant population (2013)',\n       'Second largest migrant population by country of birth (2013)',\n       '% of second largest migrant population (2013)',\n       'Third largest migrant population by country of birth (2013)',\n       '% of third largest migrant population (2013)',\n       '% of population from BAME groups (2013)',\n       '% people aged 3+ whose main language is not English (2011 census)',\n       'Overseas nationals entering the UK (NINo), (2013/14)',\n       'New migrant (NINo) rates, (2013/14)', 'Employment rate (%) (2013/14)',\n       'Male employment rate (2013/14)', 'Female employment rate (2013/14)',\n       'Unemployment rate (2013/14)', 'Youth Unemployment rate (2013/14)',\n       'Proportion of 16-18 year olds who are NEET (%) (2013)',\n       'Proportion of the working-age population who claim benefits (%) (Feb-2014)',\n       '% working-age with a disability (2012)',\n       'Proportion of working age people with no qualifications (%) 2013',\n       'Proportion of working age people in London with degree or equivalent and above (%) 2013',\n       'Gross Annual Pay, (2013)', 'Gross Annual Pay - Male (2013)',\n       'Gross Annual Pay - Female (2013)',\n       '% adults that volunteered in past 12 months (2010/11 to 2012/13)',\n       'Number of jobs by workplace (2012)',\n       '% of employment that is in public sector (2012)', 'Jobs Density, 2012',\n       'Number of active businesses, 2012',\n       'Two-year business survival rates 2012',\n       'Crime rates per thousand population 2013/14',\n       'Fires per thousand population (2013)',\n       'Ambulance incidents per hundred population (2013)',\n       'Median House Price, 2013',\n       'Average Band D Council Tax charge (£), 2014/15',\n       'New Homes (net) 2012/13', 'Homes Owned outright, (2013) %',\n       'Being bought with mortgage or loan, (2013) %',\n       'Rented from Local Authority or Housing Association, (2013) %',\n       'Rented from Private landlord, (2013) %',\n       '% of area that is Greenspace, 2005', 'Total carbon emissions (2012)',\n       'Household Waste Recycling Rate, 2012/13',\n       'Number of cars, (2011 Census)',\n       'Number of cars per household, (2011 Census)',\n       '% of adults who cycle at least once per month, 2011/12',\n       'Average Public Transport Accessibility score, 2012',\n       'Indices of Multiple Deprivation 2010 Rank of Average Score',\n       'Income Support claimant rate (Feb-14)',\n       '% children living in out-of-work families (2013)',\n       'Achievement of 5 or more A*- C grades at GCSE or equivalent including English and Maths, 2012/13',\n       'Rates of Children Looked After (2013)',\n       '% of pupils whose first language is not English (2014)',\n       'Male life expectancy, (2010-12)', 'Female life expectancy, (2010-12)',\n       'Teenage conception rate (2012)',\n       'Life satisfaction score 2012-13 (out of 10)',\n       'Worthwhileness score 2012-13 (out of 10)',\n       'Happiness score 2012-13 (out of 10)',\n       'Anxiety score 2012-13 (out of 10)', 'Political control in council',\n       'Proportion of seats won by Conservatives in 2014 election',\n       'Proportion of seats won by Labour in 2014 election',\n       'Proportion of seats won by Lib Dems in 2014 election',\n       'Turnout at 2014 local elections'],\n      dtype='object')\n```\n:::\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Code</th>\n      <th>Area/INDICATOR</th>\n      <th>Inner/ Outer London</th>\n      <th>GLA Population Estimate 2013</th>\n      <th>GLA Household Estimate 2013</th>\n      <th>Inland Area (Hectares)</th>\n      <th>Population density (per hectare) 2013</th>\n      <th>Average Age, 2013</th>\n      <th>Proportion of population aged 0-15, 2013</th>\n      <th>Proportion of population of working-age, 2013</th>\n      <th>...</th>\n      <th>Teenage conception rate (2012)</th>\n      <th>Life satisfaction score 2012-13 (out of 10)</th>\n      <th>Worthwhileness score 2012-13 (out of 10)</th>\n      <th>Happiness score 2012-13 (out of 10)</th>\n      <th>Anxiety score 2012-13 (out of 10)</th>\n      <th>Political control in council</th>\n      <th>Proportion of seats won by Conservatives in 2014 election</th>\n      <th>Proportion of seats won by Labour in 2014 election</th>\n      <th>Proportion of seats won by Lib Dems in 2014 election</th>\n      <th>Turnout at 2014 local elections</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>E09000001</td>\n      <td>City of London</td>\n      <td>Inner London</td>\n      <td>8000</td>\n      <td>4514.371383</td>\n      <td>290.4</td>\n      <td>27.525868</td>\n      <td>41.303887</td>\n      <td>7.948036</td>\n      <td>77.541617</td>\n      <td>...</td>\n      <td>.</td>\n      <td>8.10</td>\n      <td>8.23</td>\n      <td>7.44</td>\n      <td>x</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>E09000002</td>\n      <td>Barking and Dagenham</td>\n      <td>Outer London</td>\n      <td>195600</td>\n      <td>73261.408580</td>\n      <td>3610.8</td>\n      <td>54.160527</td>\n      <td>33.228935</td>\n      <td>26.072939</td>\n      <td>63.835021</td>\n      <td>...</td>\n      <td>35.4</td>\n      <td>7.06</td>\n      <td>7.57</td>\n      <td>6.97</td>\n      <td>3.3</td>\n      <td>Lab</td>\n      <td>0.000000</td>\n      <td>100.000000</td>\n      <td>0.000000</td>\n      <td>38.16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E09000003</td>\n      <td>Barnet</td>\n      <td>Outer London</td>\n      <td>370000</td>\n      <td>141385.794900</td>\n      <td>8674.8</td>\n      <td>42.651374</td>\n      <td>36.896246</td>\n      <td>20.886408</td>\n      <td>65.505593</td>\n      <td>...</td>\n      <td>14.7</td>\n      <td>7.35</td>\n      <td>7.79</td>\n      <td>7.27</td>\n      <td>2.63</td>\n      <td>Cons</td>\n      <td>50.793651</td>\n      <td>42.857143</td>\n      <td>1.587302</td>\n      <td>41.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>E09000004</td>\n      <td>Bexley</td>\n      <td>Outer London</td>\n      <td>236500</td>\n      <td>94701.226400</td>\n      <td>6058.1</td>\n      <td>39.044243</td>\n      <td>38.883039</td>\n      <td>20.282830</td>\n      <td>63.146450</td>\n      <td>...</td>\n      <td>25.8</td>\n      <td>7.47</td>\n      <td>7.75</td>\n      <td>7.21</td>\n      <td>3.22</td>\n      <td>Cons</td>\n      <td>71.428571</td>\n      <td>23.809524</td>\n      <td>0.000000</td>\n      <td>not avail</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>E09000005</td>\n      <td>Brent</td>\n      <td>Outer London</td>\n      <td>320200</td>\n      <td>114318.553900</td>\n      <td>4323.3</td>\n      <td>74.063670</td>\n      <td>35.262694</td>\n      <td>20.462585</td>\n      <td>68.714872</td>\n      <td>...</td>\n      <td>19.6</td>\n      <td>7.23</td>\n      <td>7.32</td>\n      <td>7.09</td>\n      <td>3.33</td>\n      <td>Lab</td>\n      <td>9.523810</td>\n      <td>88.888889</td>\n      <td>1.587302</td>\n      <td>33</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 76 columns</p>\n</div>\n```\n:::\n:::\n\n\nLots of different features. We also have really odd NaN values such as x and not available. We can try and get rid of this.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndef isnumber(x):\n    try:\n        float(x)\n        return True\n    except:\n        if (len(x) > 1) & (\"not avail\" not in x):\n            return True\n        else:\n            return False\n\n# apply isnumber function to every element\ndf = df[df.applymap(isnumber)]\ndf.head()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/7v/zl9mv52s3ls94kntlt_l9ryh0000gq/T/ipykernel_80700/310294434.py:12: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  df = df[df.applymap(isnumber)]\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Code</th>\n      <th>Area/INDICATOR</th>\n      <th>Inner/ Outer London</th>\n      <th>GLA Population Estimate 2013</th>\n      <th>GLA Household Estimate 2013</th>\n      <th>Inland Area (Hectares)</th>\n      <th>Population density (per hectare) 2013</th>\n      <th>Average Age, 2013</th>\n      <th>Proportion of population aged 0-15, 2013</th>\n      <th>Proportion of population of working-age, 2013</th>\n      <th>...</th>\n      <th>Teenage conception rate (2012)</th>\n      <th>Life satisfaction score 2012-13 (out of 10)</th>\n      <th>Worthwhileness score 2012-13 (out of 10)</th>\n      <th>Happiness score 2012-13 (out of 10)</th>\n      <th>Anxiety score 2012-13 (out of 10)</th>\n      <th>Political control in council</th>\n      <th>Proportion of seats won by Conservatives in 2014 election</th>\n      <th>Proportion of seats won by Labour in 2014 election</th>\n      <th>Proportion of seats won by Lib Dems in 2014 election</th>\n      <th>Turnout at 2014 local elections</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>E09000001</td>\n      <td>City of London</td>\n      <td>Inner London</td>\n      <td>8000</td>\n      <td>4514.371383</td>\n      <td>290.4</td>\n      <td>27.525868</td>\n      <td>41.303887</td>\n      <td>7.948036</td>\n      <td>77.541617</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>8.10</td>\n      <td>8.23</td>\n      <td>7.44</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>E09000002</td>\n      <td>Barking and Dagenham</td>\n      <td>Outer London</td>\n      <td>195600</td>\n      <td>73261.408580</td>\n      <td>3610.8</td>\n      <td>54.160527</td>\n      <td>33.228935</td>\n      <td>26.072939</td>\n      <td>63.835021</td>\n      <td>...</td>\n      <td>35.4</td>\n      <td>7.06</td>\n      <td>7.57</td>\n      <td>6.97</td>\n      <td>3.3</td>\n      <td>Lab</td>\n      <td>0.000000</td>\n      <td>100.000000</td>\n      <td>0.000000</td>\n      <td>38.16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E09000003</td>\n      <td>Barnet</td>\n      <td>Outer London</td>\n      <td>370000</td>\n      <td>141385.794900</td>\n      <td>8674.8</td>\n      <td>42.651374</td>\n      <td>36.896246</td>\n      <td>20.886408</td>\n      <td>65.505593</td>\n      <td>...</td>\n      <td>14.7</td>\n      <td>7.35</td>\n      <td>7.79</td>\n      <td>7.27</td>\n      <td>2.63</td>\n      <td>Cons</td>\n      <td>50.793651</td>\n      <td>42.857143</td>\n      <td>1.587302</td>\n      <td>41.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>E09000004</td>\n      <td>Bexley</td>\n      <td>Outer London</td>\n      <td>236500</td>\n      <td>94701.226400</td>\n      <td>6058.1</td>\n      <td>39.044243</td>\n      <td>38.883039</td>\n      <td>20.282830</td>\n      <td>63.146450</td>\n      <td>...</td>\n      <td>25.8</td>\n      <td>7.47</td>\n      <td>7.75</td>\n      <td>7.21</td>\n      <td>3.22</td>\n      <td>Cons</td>\n      <td>71.428571</td>\n      <td>23.809524</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>E09000005</td>\n      <td>Brent</td>\n      <td>Outer London</td>\n      <td>320200</td>\n      <td>114318.553900</td>\n      <td>4323.3</td>\n      <td>74.063670</td>\n      <td>35.262694</td>\n      <td>20.462585</td>\n      <td>68.714872</td>\n      <td>...</td>\n      <td>19.6</td>\n      <td>7.23</td>\n      <td>7.32</td>\n      <td>7.09</td>\n      <td>3.33</td>\n      <td>Lab</td>\n      <td>9.523810</td>\n      <td>88.888889</td>\n      <td>1.587302</td>\n      <td>33</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 76 columns</p>\n</div>\n```\n:::\n:::\n\n\nThat looks much cleaner.\n\nReplace the NaN values in numeric columns with the mean.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# get only numeric columns\nnumericColumns = df._get_numeric_data()\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.metrics import euclidean_distances\n\n# keep place names and store them in a variable\nplaceNames = df[\"Area/INDICATOR\"]\n\n# let's fill the missing values with mean()\nnumericColumns = numericColumns.fillna(numericColumns.mean())\n\n# let's centralize the data\nnumericColumns -= numericColumns.mean()\n\n# now we compute the euclidean distances between the columns by passing the same data twice\n# the resulting data matrix now has the pairwise distances between the boroughs.\n# CAUTION: note that we are now building a distance matrix in a high-dimensional data space\n# remember the Curse of Dimensionality -- we need to be cautious with the distance values\ndistMatrix = euclidean_distances(numericColumns, numericColumns)\n```\n:::\n\n\nCheck to make sure everything looks ok.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nnumericColumns.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GLA Population Estimate 2013</th>\n      <th>GLA Household Estimate 2013</th>\n      <th>Inland Area (Hectares)</th>\n      <th>Population density (per hectare) 2013</th>\n      <th>Average Age, 2013</th>\n      <th>Proportion of population aged 0-15, 2013</th>\n      <th>Proportion of population of working-age, 2013</th>\n      <th>Proportion of population aged 65 and over, 2013</th>\n      <th>% of population from BAME groups (2013)</th>\n      <th>% people aged 3+ whose main language is not English (2011 census)</th>\n      <th>...</th>\n      <th>Average Public Transport Accessibility score, 2012</th>\n      <th>Indices of Multiple Deprivation 2010 Rank of Average Score</th>\n      <th>Income Support claimant rate (Feb-14)</th>\n      <th>Rates of Children Looked After (2013)</th>\n      <th>Life satisfaction score 2012-13 (out of 10)</th>\n      <th>Worthwhileness score 2012-13 (out of 10)</th>\n      <th>Happiness score 2012-13 (out of 10)</th>\n      <th>Proportion of seats won by Conservatives in 2014 election</th>\n      <th>Proportion of seats won by Labour in 2014 election</th>\n      <th>Proportion of seats won by Lib Dems in 2014 election</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-247760.606061</td>\n      <td>-97761.616805</td>\n      <td>-4473.681818</td>\n      <td>-43.279630</td>\n      <td>5.426932</td>\n      <td>-11.500067</td>\n      <td>8.480871</td>\n      <td>3.019196</td>\n      <td>-17.390874</td>\n      <td>-4.491385</td>\n      <td>...</td>\n      <td>3.753658</td>\n      <td>157.424242</td>\n      <td>-1.726749</td>\n      <td>42.212121</td>\n      <td>0.816364</td>\n      <td>0.651212</td>\n      <td>0.23303</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-8.881784e-16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-60160.606061</td>\n      <td>-29014.579608</td>\n      <td>-1153.281818</td>\n      <td>-16.644971</td>\n      <td>-2.648021</td>\n      <td>6.624837</td>\n      <td>-5.225725</td>\n      <td>-1.399112</td>\n      <td>5.764246</td>\n      <td>-2.905288</td>\n      <td>...</td>\n      <td>-0.882730</td>\n      <td>-82.575758</td>\n      <td>1.787041</td>\n      <td>20.212121</td>\n      <td>-0.223636</td>\n      <td>-0.008788</td>\n      <td>-0.23697</td>\n      <td>-32.854444</td>\n      <td>43.384181</td>\n      <td>-6.598065e+00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>114239.393939</td>\n      <td>39109.806712</td>\n      <td>3910.718182</td>\n      <td>-28.154125</td>\n      <td>1.019290</td>\n      <td>1.438305</td>\n      <td>-3.555153</td>\n      <td>2.116847</td>\n      <td>-2.799300</td>\n      <td>1.775548</td>\n      <td>...</td>\n      <td>-0.883020</td>\n      <td>71.424242</td>\n      <td>-0.517827</td>\n      <td>-18.787879</td>\n      <td>0.066364</td>\n      <td>0.211212</td>\n      <td>0.06303</td>\n      <td>17.939207</td>\n      <td>-13.758676</td>\n      <td>-5.010764e+00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-19260.606061</td>\n      <td>-7574.761788</td>\n      <td>1294.018182</td>\n      <td>-31.761255</td>\n      <td>3.006083</td>\n      <td>0.834727</td>\n      <td>-5.914296</td>\n      <td>5.079569</td>\n      <td>-20.328016</td>\n      <td>-15.598200</td>\n      <td>...</td>\n      <td>-1.364540</td>\n      <td>69.424242</td>\n      <td>-0.018377</td>\n      <td>-8.787879</td>\n      <td>0.186364</td>\n      <td>0.171212</td>\n      <td>0.00303</td>\n      <td>38.574127</td>\n      <td>-32.806295</td>\n      <td>-6.598065e+00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>64439.393939</td>\n      <td>12042.565712</td>\n      <td>-440.781818</td>\n      <td>3.258171</td>\n      <td>-0.614262</td>\n      <td>1.014482</td>\n      <td>-0.345874</td>\n      <td>-0.668608</td>\n      <td>25.000030</td>\n      <td>15.521631</td>\n      <td>...</td>\n      <td>-0.174795</td>\n      <td>-69.575758</td>\n      <td>0.001370</td>\n      <td>-6.787879</td>\n      <td>-0.053636</td>\n      <td>-0.258788</td>\n      <td>-0.11697</td>\n      <td>-23.330634</td>\n      <td>32.273070</td>\n      <td>-5.010764e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>\n```\n:::\n:::\n\n\nWe can plot out our many dimension space by uncommenting the code below (also note down how long does this take).\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n#import seaborn as sns\n#sns_plot = sns.pairplot(numericColumns)\n#sns_plot.savefig(\"figs/output.png\")\n```\n:::\n\n\nGiven that this takes quite a while (around 10 minutes), this is the image that would result from uncommenting and running the code above.\n\n![](figs/output.png)\n\nDimension reduction will help us here!\n\nWe could apply various different types of dimension reduction here. We are specifically going to capture the dissimilarity in the data using [multidimensional scaling](https://scikit-learn.org/stable/modules/manifold.html#multidimensional-scaling). Our distance matrix will come in useful here.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn import manifold\n# for instance, typing distMatrix.shape on the console gives:\n# Out[115]: (38, 38) # i.e., the number of rows\n\n# first we generate an MDS object and extract the projections\nmds = manifold.MDS(n_components = 2, max_iter=3000, n_init=1, dissimilarity=\"precomputed\", normalized_stress=False)\nY = mds.fit_transform(distMatrix)\n```\n:::\n\n\nTo interpret what is happening, let us plot the boroughs on the projected two dimensional space.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfrom matplotlib import pyplot as plt\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15, 15)\nplt.suptitle('MDS on only London boroughs')\nax.scatter(Y[:, 0], Y[:, 1], c=\"#D06B36\", s = 100, alpha = 0.8, linewidth=0)\n\nfor i, txt in enumerate(placeNames):\n    ax.annotate(txt, (Y[:, 0][i],Y[:, 1][i]))\n```\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_5_3_files/figure-html/cell-10-output-1.png){width=1240 height=1294}\n:::\n:::\n\n\nOur data also include happiness metrics. Pulling these out of our data and carrying out more multidimensional scaling can help us see how the boroughs differ in happiness.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# get the data columns relating to emotions and feelings\ndataOnEmotions = numericColumns[[\"Life satisfaction score 2012-13 (out of 10)\", \"Worthwhileness score 2012-13 (out of 10)\",\"Happiness score 2012-13 (out of 10)\"]]\n\n# a new distance matrix to represent \"emotional distance\"s\ndistMatrix2 = euclidean_distances(dataOnEmotions, dataOnEmotions)\n\n# compute a new \"embedding\" (machine learners' word for projection)\nY2 = mds.fit_transform(distMatrix2)\n\n# let's look at the results\nfig, ax = plt.subplots()\nfig.set_size_inches(15, 15)\nplt.suptitle('An \\\"emotional\\\" look at London boroughs')\nax.scatter(Y2[:, 0], Y2[:, 1], c=\"#D06B36\", s = 100, alpha = 0.8, linewidth=0)\n\nfor i, txt in enumerate(placeNames):\n    ax.annotate(txt, (Y2[:, 0][i],Y2[:, 1][i]))\n```\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_5_3_files/figure-html/cell-11-output-1.png){width=1298 height=1294}\n:::\n:::\n\n\nThe location of the different boroughs on the 2 dimensional multidimensional scaling space from the happiness metrics is\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nresults_fixed = Y2.copy()\nprint(results_fixed)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[ 0.2271398  -1.04240068]\n [ 0.26251126  0.17972657]\n [ 0.00390035 -0.21903333]\n [ 0.00138482 -0.2617964 ]\n [-0.02236505  0.2944913 ]\n [-0.17389157 -0.41496015]\n [-0.01597349  0.23197449]\n [ 0.09765126  0.29907574]\n [-0.25905729  0.05671686]\n [-0.22523866  0.02833316]\n [ 0.13044353  0.16816905]\n [ 0.16297356  0.27561721]\n [ 0.2595173   0.06555536]\n [ 0.02948884  0.17346685]\n [-0.16592169 -0.03144032]\n [-0.04671937 -0.13903436]\n [-0.12595688 -0.10674683]\n [-0.0792539  -0.04423151]\n [ 0.17722654  0.52220617]\n [-0.21816217 -0.57321356]\n [-0.03620132  0.11992019]\n [ 0.19240728  0.29779961]\n [ 0.12618701 -0.06185706]\n [ 0.07368873  0.10010972]\n [-0.12722117  0.06315405]\n [-0.1777722   0.09054863]\n [-0.1150014  -0.19368075]\n [ 0.03991431 -0.07060854]\n [ 0.0647058   0.04268436]\n [-0.11578733 -0.00896943]\n [ 0.02696866 -0.11011052]\n [-0.07633466  0.03385581]\n [ 0.1047491   0.23467831]]\n```\n:::\n:::\n\n\nWe may want to look at if the general happiness rating captures the position of the boroughs. To do this we need to assign colours based on the binned happiness score.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nimport numpy as np\n\ncolorMappingValuesHappiness = np.asarray(dataOnEmotions[[\"Life satisfaction score 2012-13 (out of 10)\"]]).flatten()\nprint(results_fixed.shape)\ncolorMappingValuesHappiness.shape\n\ncolorMappingValuesHappiness\n#c = colorMappingValuesCrime, cmap = plt.cm.Greens\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(33, 2)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\narray([ 0.81636364, -0.22363636,  0.06636364,  0.18636364, -0.05363636,\n        0.34636364, -0.06363636, -0.28363636, -0.04363636, -0.10363636,\n       -0.12363636, -0.21363636, -0.05363636, -0.08363636,  0.05636364,\n        0.11636364,  0.06636364,  0.01636364, -0.20363636,  0.39636364,\n        0.00636364, -0.19363636, -0.05363636, -0.10363636, -0.06363636,\n       -0.00363636,  0.13636364, -0.01363636, -0.03363636, -0.00363636,\n       -0.04363636, -0.05363636, -0.19363636])\n```\n:::\n:::\n\n\nFinally, we can plot this. What can you see?\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# let's look at the results\nfig, ax = plt.subplots()\nfig.set_size_inches(15, 15)\nplt.suptitle('An \\\"emotional\\\" look at London boroughs')\n#ax.scatter(results_fixed[:, 0], results_fixed[:, 1], c = colorMappingValuesHappiness, cmap='viridis')\nplt.scatter(results_fixed[:, 0], results_fixed[:, 1], c = colorMappingValuesHappiness, s = 100, cmap=plt.cm.Greens)\n\nfor i, txt in enumerate(placeNames):\n    ax.annotate(txt, (results_fixed[:, 0][i],results_fixed[:, 1][i]))\n```\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_5_3_files/figure-html/cell-14-output-1.png){width=1298 height=1294}\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# get the data columns relating to emotions and feelings\ndataOnDiversity = numericColumns[[\"Proportion of population aged 0-15, 2013\", \"Proportion of population of working-age, 2013\", \"Proportion of population aged 65 and over, 2013\", \"% of population from BAME groups (2013)\", \"% people aged 3+ whose main language is not English (2011 census)\"]]\n\n# a new distance matrix to represent \"emotional distance\"s\ndistMatrix3 = euclidean_distances(dataOnDiversity, dataOnDiversity)\n\nmds = manifold.MDS(n_components = 2, max_iter=3000, n_init=1, dissimilarity=\"precomputed\", normalized_stress = False)\nY = mds.fit_transform(distMatrix3)\n\n# Visualising the data.\nfig, ax = plt.subplots()\nfig.set_size_inches(15, 15)\nplt.suptitle('An \\\"diversity\\\" look at London boroughs')\nax.scatter(Y[:, 0], Y[:, 1], s = 100, c = colorMappingValuesHappiness, cmap=plt.cm.Greens)\n\nfor i, txt in enumerate(placeNames):\n    ax.annotate(txt, (Y[:, 0][i],Y[:, 1][i]))\n```\n\n::: {.cell-output .cell-output-display}\n![](IM939_Lab_5_3_files/figure-html/cell-15-output-1.png){width=1218 height=1294}\n:::\n:::\n\n\nThis looks very different to the one above on \"emotion\" related variables. Our job now is to relate these two projections to one another. Do you see similarities? Do you see clusters of boroughs? Can you reflect on how you can relate and combine these two maps conceptually?\n\n### A small TODO for you:\n\nQ: Can you think of other maps that you can produce with this data? Have a look at the variables once again and try to produce new \"perspectives\" to the data and see what they have to say.\n\n\n",
    "supporting": [
      "IM939_Lab_5_3_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}