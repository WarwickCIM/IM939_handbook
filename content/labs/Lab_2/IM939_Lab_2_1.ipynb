{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Pandas\n",
    "\n",
    "Last week we loaded data using [`pandas`](https://pandas.pydata.org/)' `read.csv()` method, but Pandas can do way more than that. Pandas is an essential library for data science, as it provides the data structures (nameley, `series` -1D- and `data frames` -2D) and operations for manipulating tabular data. \n",
    "\n",
    "In this unit's labs we will be using `pandas` to read in, process and explore data (this notebook); create (basic) visualisations capabilities (@sec-pandas-datavis) as well as transforming data (@sec-pandas-transforming-data). To do so, we will be using a dataset about _\"The Office\"_.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "[_The Office_](https://www.imdb.com/title/tt0386676/?ref_=ttep_ov) is a humoristic TV series originally created in 2001 by Ricky Gervais and Stephen Merchant that has received several adaptations. The dataset that we will be using contains information (i.e., title, date and ratings from [IMBDB](https://www.imdb.com/title/tt0386676/?ref_=ttep_ov)) about every episode of the 9 seaons of the very successful USA's adaptation aired between 2005 and 2013.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"img/the_office.png\" alt=\"The Office promotional poster\" style=\"width: 400px;\"/>\n",
    "\n",
    "The dataset is stored in a `csv` file that has the following columns: `season`, `episode`, `title`, `imdb_rating`, `total_votes`, `air_date`.\n",
    "\n",
    "\n",
    "## Starting\n",
    "\n",
    "To work with the dataset we will need to _import_ pandas so we can use every feature provided by the library, as well as loading the dataset stored in the `office_ratings.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two lines are added so that not all the warnings are rendered in the cell. \n",
    "# We do this not to confuse you during your learning journey with some of the warnings but \n",
    "# normally you would want them turned on since they can tell you something about things that might not be working as expected.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this following import will always be needed whenever you want to work with Pandas.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/raw/office_ratings.csv', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help!\n",
    "\n",
    "Python has inbuilt documentation. To access this add a `?` before an object or method.\n",
    "\n",
    "::: callout-note\n",
    "\n",
    "The output of the help function has been omitted in the handbook. Please run the cells in your notebook to read the different outputs\n",
    "\n",
    ":::\n",
    "\n",
    "For example, our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the `dtypes` property\n",
    "\n",
    "::: callout-tip\n",
    "\n",
    "Properties of object are values associated with the object and are not called with a `()` at the end.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `info` method for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to get help in-line like the examples above, that can give a very long help message that might not be always convenient. If you like, you can try to get the help for this following function like this:\n",
    "\n",
    "> ?pd.read_csv\n",
    "\n",
    "However, the below will be quite long -- it provides you the various arguments (options) you can use with the method. \n",
    "\n",
    "Instead of this approach, a much better way to get help is to refer to the documentation and the API of the library that you are using. For instance, for `read_csv()`, this page is much more useful -- https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html \n",
    "\n",
    "We recommend that you use a search engine very frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas documentation is rather good. Relevent to our below work is:\n",
    "\n",
    "* [What kind of data does pandas handle?](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/01_table_oriented.html#min-tut-01-tableoriented)\n",
    "* [How to calculate summary statistics?](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/01_table_oriented.html#min-tut-01-tableoriented)\n",
    "* [How to create plots in pandas?](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/04_plotting.html#min-tut-04-plotting)\n",
    "* [How to handle time series data with ease?](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/09_timeseries.html#min-tut-09-timeseries)\n",
    "\n",
    "I also found [a rather nice series of lessons a kind person put together](https://bitbucket.org/hrojas/learn-pandas/src/master/). There are lots of online tutorials which will help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In @sec-data-types we introduced Python's data types as well as how to use the function `type()` to retrieve an object's data type. Pandas expands python's data types by creating a new one called `data frame` \n",
    "\n",
    "::: aside\n",
    "\n",
    "Do you remember what are Python's data types? You can refer to @sec-data-types for a refresher and to know more about them.\n",
    "\n",
    ":::\n",
    "\n",
    "::: callout-tip\n",
    "\n",
    "### Data frames\n",
    "\n",
    "Data frames are 2-dimensional data structures that store information in columns and rows, very much like data is stored in a spreadsheet or a database. Typically, every column will contain variables (or sometimes called attributes) whereas every row represents an observation. This is known as wide data frames, as opposed to long data frames.\n",
    "\n",
    "In pandas, every column has a name and rows can be named, too. \n",
    "\n",
    ":::\n",
    "\n",
    "So let's check the what our newly created object's (`df`) data type:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, `df` is a `DataFrame`` object, provided by pandas.\n",
    "\n",
    "The `DataFrame` object has lots of built in _methods_ and _attributes_.\n",
    "\n",
    "The `info` method gives us information about datatypes, dimensions and the presence of null values in our dataframe. Let's see how can we use it and what information is returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just `dtypes` to check the data types of every variable in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or just the dimensions (e.g., rows and columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there are only 188 rows. But for larger datasets we might want to look at the head (top 5) and tail (bottom 5) rows using `.head()` and `.tail()`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "To get an overview of our data we can ask Python to '_describe_ our (numeric) data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we can pull out specific statistics for numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the error triggered above due to pandas attempting to calculate the mean of the wrong type (i.e. non-numeric values). We can address that by only computing the mean of numeric values (see below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the sum of every value within the same column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to what happened with `mean()`, `sum()` is adding all values in every observation of every attribute, regardless of their type, but this time is not producing an error. Can you see what happens with strings? And with dates?\n",
    "\n",
    "Again, we can force to use numeric values only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting\n",
    "\n",
    "Often times we may have a large dataset and we only need to work with just a part of it (a subset) consisting of certain columns and/or rows. Selecting specific columns and/or rows is known as subsetting.\n",
    "\n",
    "### Selecting columns\n",
    "\n",
    "Because in pandas every column has a name, we can select columns by their name or their position.\n",
    "\n",
    "#### Selecting by name\n",
    "\n",
    "To select by name we will use the syntax `df['<column_name>']`. For example, if we wanted to select the ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['imdb_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we could select the date in which the chapters were first aired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['air_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even select more than one column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['imdb_rating', 'total_votes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: callout-important\n",
    "\n",
    "Did you notice that we used two sets of squared brackets (`[[]]`)? This is needed because we need to passing a _list_ of the column names to the [`__getitem__`](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#basics) method of the pandas dataframe object, and as you may remember from @sec-list-dictionaries, this is the syntax used for lists (thank [this stackoverflow question](https://stackoverflow.com/questions/11285613/selecting-multiple-columns-in-a-pandas-dataframe)). \n",
    "\n",
    "This is what we'd get otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| error: true\n",
    "df['imdb_rating', 'total_votes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check out the pandas documentation on [indexing and selecting data](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#basics).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply methods to subset, such as this one to get the average rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['imdb_rating'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to calculate the total number of votes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_votes'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a combination of multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['imdb_rating', 'total_votes']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting by position\n",
    "\n",
    "If we do not want to use column names, we can use `iloc` method by using the syntax `<object>.iloc[<row slice>, <column slice>]`, where a slice is a range of numbers separated by a colon `:`. So, if we were to select the value in the 4th row and 2nd column, we'd use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we just wanted to select a column? In that case, we can use the same method but instead of specifiying a row, we will need to use `:` to indicate that we are selecting all the rows, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversely, if we just wanted to select all the columns from a given row, we'd use `:` on the right side of the `,` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use negative values in indexes to indicate 'from the end'. So, an index of [-10, :] returns the 10th from last row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using tail, we could ask for the last 5 rows with an index of `[-5:, :]`. I read `:` as 'and everything else' in these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-5:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the row is shown on the left. That will stop you getting lost in slices of the data. \n",
    "\n",
    "For the top ten rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can run methods on these slices. We could, if we wanted to, calculate the mean imdb rating of only the first and last 100 episodes. _Note_ the indexing starts at 0 so we want the column index of 3 (0:season, 1:episode, 2:title, 3:imdb_rating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:100,3].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-100:,3].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are unsure how many rows you have then the count method comes to the rescue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-100:,3].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like the last 100 episodes were less good than the first 100. I guess that is why it was cancelled.\n",
    "\n",
    "Our data is organised by season. Looking at the average by season might help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['season', 'imdb_rating']].groupby('season').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line groups our dataframe by values in the season column and then displays the mean for each group. Pretty nifty.\n",
    "\n",
    "Season 8 looks pretty bad. We can look at just the rows for season 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['season'] == 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering rows\n",
    "\n",
    "We can filter rows matching some criteria by using the syntax `<object>.loc[<criteria>]`.  So, if we wanted to filter all the episodes from the 8th season, we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['season'] == 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: callout-note\n",
    "\n",
    "### Understanding the criteria\n",
    "\n",
    "To understand why we have to write the name of the dataframe twice, we can focus on the output provided by the filtering criteria only:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['season'] == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it returns a boolean serie specifiying which rows are matching the criteria (`True`) and which ones are not (`False`)\n",
    "\n",
    "As a side note, while writing the name of the dataframe twice may seem redundant, this means that we could filter rows based on other objects.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get an overview of the rating of all chapters within season 8 by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['season'] == 8, 'imdb_rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally pretty bad, but there is clearly one very disliked episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding columns\n",
    "\n",
    "We can add new columns pretty simply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x'] = 44\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new column can be an operation on other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating_div_total_votes'] = df['imdb_rating'] / df['total_votes']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or as simple as adding one to every value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['season'] + 1\n",
    "df.iloc[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  df['season'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data\n",
    "\n",
    "Pandas supports writing out data frames to various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?df.to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can uncomment the code below to save your dataframe into a csv file. But before doing so, check that your `data/output` folder is empty, as it would override its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "df.to_csv('data/output/my_output_ratings.csv', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we could export our dataset to an excel file by using `to_excel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?df.to_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can uncomment the code below to save your dataframe into an excel file. But before doing so, check that your `data/output` folder is empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel('data/output/my_output_ratings.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining datasets\n",
    "\n",
    "\n",
    "In this notebook, our dataset was created from a single file that contained all the data that was needed. However, often times data will be spread into different files that we will need to combine to create our own dataset.\n",
    "\n",
    "Consider the two dataframes below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('data/raw/office1.csv', encoding='UTF-8')\n",
    "df_2 = pd.read_csv('data/raw/office2.csv', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the total votes and imdb ratings data are split between files that we will need to combine. Usually this is done by using a shared column between the two datasets that works as an index. Gladly, `head()` reveals that in both cases there is a common column called `id`. We can _join_ the two dataframes together using the common column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join_office_df = pd.merge(df_1, df_2, on='id', how='inner')\n",
    "inner_join_office_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way you can combine datasets using common columns and an _inner join_. We will leave that for the moment. If you want more information about merging data then see [this page](https://www.datasciencemadesimple.com/join-merge-data-frames-pandas-python/#:~:text=Merge%20%28%29%20Function%20in%20pandas%20is%20similar%20to,rows%20from%20both%20data%20frames%2C%20specify%20how%3D%20%E2%80%98outer%E2%80%99.) and the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well done!\n",
    "\n",
    "Well done! You've reached the end of a pretty long notebook that went through a lot of details about how to work with this pretty critical package called Pandas. We haven't really done a lot of detailed analysis in this one yet but we will use Pandas a lot and frequently.\n",
    "\n",
    "Your best friend will be the Pandas documentation -- https://pandas.pydata.org/docs/index.html\n",
    "\n",
    "This documentation is great. We particuarly recomment the User Guide that will answer most of your questions and will give you a lot of code to copy and paste first and then modify to do what you need to do -- https://pandas.pydata.org/docs/user_guide/index.html#user-guide\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
