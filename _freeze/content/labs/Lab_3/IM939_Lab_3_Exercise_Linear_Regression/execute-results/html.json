{
  "hash": "fc84d0ca27589b492766bb6091a6b8f4",
  "result": {
    "engine": "jupyter",
    "markdown": "::: {#cell-0 .cell execution_count=1}\n``` {.python .cell-code}\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n:::\n\n\n# Exercise: Regression\n\nNow it's your turn to prepare a linear regression model.\n\n## Scikit Learn\n\nYou can use here as well Scikit Learn library. More information you can find here:\n<https://www.tutorialspoint.com/scikit_learn/scikit_learn_linear_regression.htm>\n\n\n## Wine Dataset\n\nFor this exercise we will be using Wine Quality Dataset from @cortezWineQuality2009. You can find more information about it here: <https://doi.org/10.24432/C56S3T>\n\nWhat would be your research question? What do you like to learn, given the data you have?\n\n## Reading Data\n\n::: {#cell-5 .cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n```\n:::\n\n\n::: {#cell-6 .cell execution_count=3}\n``` {.python .cell-code}\nwine = pd.read_excel('data/raw/winequality-red_v2.xlsx', engine = 'openpyxl')\n\n#You might need to use encoding, then the code will look like:\n# wine = pd.read_excel('data/raw/winequality-red_v2.xlsx', engine = 'openpyxl', encoding='UTF-8')\n```\n:::\n\n\n## Data exploration\nLet's check the data, their distribution and central tendencies\n\n::: {#cell-8 .cell execution_count=4}\n``` {.python .cell-code}\nprint('shape:', wine.shape)\nwine.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (1599, 12)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed_acidity</th>\n      <th>volatile_acidity</th>\n      <th>citric_acid</th>\n      <th>residual_sugar</th>\n      <th>chlorides</th>\n      <th>free_sulfur_dioxide</th>\n      <th>total_sulfur_dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.88</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.9968</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.76</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.9970</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.28</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.9980</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Check your variables\n\nUse lmplot() function from Seaborn to explore linear relationship \nInput data must be in a Pandas DataFrame. To plot them, we provide the predictor and response variable names along with the dataset\n\n\nDid you find outliers or missing data? \nYou can use function np.unique and find the unique elements of an array.\n\n::: {#cell-12 .cell execution_count=6}\n``` {.python .cell-code}\n?np.unique\n```\n:::\n\n\n\nDo you need to remove any cases?\n\n::: {#cell-15 .cell execution_count=8}\n``` {.python .cell-code}\n \n```\n:::\n\n\n\nDid you need to standarize data?\n\n\nIf you standarized data, try to plot them again\n\n::: {#cell-20 .cell execution_count=11}\n``` {.python .cell-code}\n \n```\n:::\n\n\n## Form ideas about the data \nBefore you move on to exploring correlations and maybe other kinds of models, try and build some sense of understanding of the relations between the variables. What are some relations that stand out. Do you know a bit more about the wines in this dataset or wines more generally?\n\n## Move on to building some simple models\n\nYou can calculates a Pearson correlation coefficient and the p-value for testing non-correlation.\n\nWe will be using the scikit-learn package here. This is a package we will be making use of very frequently.\n\n::: {#cell-23 .cell execution_count=12}\n``` {.python .cell-code}\nimport scipy.stats\nscipy.stats.pearsonr(wine.???.values, wine.???.values)\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-cyan-fg\">  Cell </span><span class=\"ansi-green-fg\">In[6], line 2</span>\n<span class=\"ansi-red-fg\">    scipy.stats.pearsonr(wine.???.values, wine.???.values)</span>\n                              ^\n<span class=\"ansi-red-fg\">SyntaxError</span><span class=\"ansi-red-fg\">:</span> invalid syntax\n</pre>\n```\n:::\n\n:::\n:::\n\n\nusing **Scikit-learn**, build a simple linear regression (OLS) \n\n::: {#cell-25 .cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\n\nest = LinearRegression(fit_intercept = True)\n\nx = wine[['???']]\ny = wine[['???']]\n\nest.fit(x, y)\n\nprint(\"Coefficients:\", est.coef_)\nprint (\"Intercept:\", est.intercept_)\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">KeyError</span>                                  Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[7], line 5</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span> <span style=\"font-weight:bold;color:rgb(0,0,255)\">sklearn</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">linear_model</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> LinearRegression\n<span class=\"ansi-green-fg ansi-bold\">      3</span> est <span style=\"color:rgb(98,98,98)\">=</span> LinearRegression(fit_intercept <span style=\"color:rgb(98,98,98)\">=</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">True</span>)\n<span class=\"ansi-green-fg\">----&gt; 5</span> x <span style=\"color:rgb(98,98,98)\">=</span> <span class=\"ansi-yellow-bg\">wine</span><span class=\"ansi-yellow-bg\">[</span><span class=\"ansi-yellow-bg\">[</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">???</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">]</span><span class=\"ansi-yellow-bg\">]</span>\n<span class=\"ansi-green-fg ansi-bold\">      6</span> y <span style=\"color:rgb(98,98,98)\">=</span> wine[[<span style=\"color:rgb(175,0,0)\">'</span><span style=\"color:rgb(175,0,0)\">???</span><span style=\"color:rgb(175,0,0)\">'</span>]]\n<span class=\"ansi-green-fg ansi-bold\">      8</span> est<span style=\"color:rgb(98,98,98)\">.</span>fit(x, y)\n\nFile <span class=\"ansi-green-fg\">~/anaconda3/envs/IM939/lib/python3.12/site-packages/pandas/core/frame.py:4108</span>, in <span class=\"ansi-cyan-fg\">DataFrame.__getitem__</span><span class=\"ansi-blue-fg\">(self, key)</span>\n<span class=\"ansi-green-fg ansi-bold\">   4106</span>     <span style=\"font-weight:bold;color:rgb(0,135,0)\">if</span> is_iterator(key):\n<span class=\"ansi-green-fg ansi-bold\">   4107</span>         key <span style=\"color:rgb(98,98,98)\">=</span> <span style=\"color:rgb(0,135,0)\">list</span>(key)\n<span class=\"ansi-green-fg\">-&gt; 4108</span>     indexer <span style=\"color:rgb(98,98,98)\">=</span> <span style=\"color:rgb(0,135,0)\" class=\"ansi-yellow-bg\">self</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-yellow-bg\">columns</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-yellow-bg\">_get_indexer_strict</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">key</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">\"</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">columns</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">\"</span><span class=\"ansi-yellow-bg\">)</span>[<span style=\"color:rgb(98,98,98)\">1</span>]\n<span class=\"ansi-green-fg ansi-bold\">   4110</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># take() does not accept boolean indexers</span>\n<span class=\"ansi-green-fg ansi-bold\">   4111</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">if</span> <span style=\"color:rgb(0,135,0)\">getattr</span>(indexer, <span style=\"color:rgb(175,0,0)\">\"</span><span style=\"color:rgb(175,0,0)\">dtype</span><span style=\"color:rgb(175,0,0)\">\"</span>, <span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>) <span style=\"color:rgb(98,98,98)\">==</span> <span style=\"color:rgb(0,135,0)\">bool</span>:\n\nFile <span class=\"ansi-green-fg\">~/anaconda3/envs/IM939/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200</span>, in <span class=\"ansi-cyan-fg\">Index._get_indexer_strict</span><span class=\"ansi-blue-fg\">(self, key, axis_name)</span>\n<span class=\"ansi-green-fg ansi-bold\">   6197</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">else</span>:\n<span class=\"ansi-green-fg ansi-bold\">   6198</span>     keyarr, indexer, new_indexer <span style=\"color:rgb(98,98,98)\">=</span> <span style=\"color:rgb(0,135,0)\">self</span><span style=\"color:rgb(98,98,98)\">.</span>_reindex_non_unique(keyarr)\n<span class=\"ansi-green-fg\">-&gt; 6200</span> <span style=\"color:rgb(0,135,0)\" class=\"ansi-yellow-bg\">self</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-yellow-bg\">_raise_if_missing</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">keyarr</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">indexer</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">axis_name</span><span class=\"ansi-yellow-bg\">)</span>\n<span class=\"ansi-green-fg ansi-bold\">   6202</span> keyarr <span style=\"color:rgb(98,98,98)\">=</span> <span style=\"color:rgb(0,135,0)\">self</span><span style=\"color:rgb(98,98,98)\">.</span>take(indexer)\n<span class=\"ansi-green-fg ansi-bold\">   6203</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">if</span> <span style=\"color:rgb(0,135,0)\">isinstance</span>(key, Index):\n<span class=\"ansi-green-fg ansi-bold\">   6204</span>     <span style=\"font-style:italic;color:rgb(95,135,135)\"># GH 42790 - Preserve name from an Index</span>\n\nFile <span class=\"ansi-green-fg\">~/anaconda3/envs/IM939/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249</span>, in <span class=\"ansi-cyan-fg\">Index._raise_if_missing</span><span class=\"ansi-blue-fg\">(self, key, indexer, axis_name)</span>\n<span class=\"ansi-green-fg ansi-bold\">   6247</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">if</span> nmissing:\n<span class=\"ansi-green-fg ansi-bold\">   6248</span>     <span style=\"font-weight:bold;color:rgb(0,135,0)\">if</span> nmissing <span style=\"color:rgb(98,98,98)\">==</span> <span style=\"color:rgb(0,135,0)\">len</span>(indexer):\n<span class=\"ansi-green-fg\">-&gt; 6249</span>         <span style=\"font-weight:bold;color:rgb(0,135,0)\">raise</span> <span style=\"font-weight:bold;color:rgb(215,95,95)\">KeyError</span>(<span style=\"color:rgb(175,0,0)\">f</span><span style=\"color:rgb(175,0,0)\">\"</span><span style=\"color:rgb(175,0,0)\">None of [</span><span style=\"font-weight:bold;color:rgb(175,95,135)\">{</span>key<span style=\"font-weight:bold;color:rgb(175,95,135)\">}</span><span style=\"color:rgb(175,0,0)\">] are in the [</span><span style=\"font-weight:bold;color:rgb(175,95,135)\">{</span>axis_name<span style=\"font-weight:bold;color:rgb(175,95,135)\">}</span><span style=\"color:rgb(175,0,0)\">]</span><span style=\"color:rgb(175,0,0)\">\"</span>)\n<span class=\"ansi-green-fg ansi-bold\">   6251</span>     not_found <span style=\"color:rgb(98,98,98)\">=</span> <span style=\"color:rgb(0,135,0)\">list</span>(ensure_index(key)[missing_mask<span style=\"color:rgb(98,98,98)\">.</span>nonzero()[<span style=\"color:rgb(98,98,98)\">0</span>]]<span style=\"color:rgb(98,98,98)\">.</span>unique())\n<span class=\"ansi-green-fg ansi-bold\">   6252</span>     <span style=\"font-weight:bold;color:rgb(0,135,0)\">raise</span> <span style=\"font-weight:bold;color:rgb(215,95,95)\">KeyError</span>(<span style=\"color:rgb(175,0,0)\">f</span><span style=\"color:rgb(175,0,0)\">\"</span><span style=\"font-weight:bold;color:rgb(175,95,135)\">{</span>not_found<span style=\"font-weight:bold;color:rgb(175,95,135)\">}</span><span style=\"color:rgb(175,0,0)\"> not in index</span><span style=\"color:rgb(175,0,0)\">\"</span>)\n\n<span class=\"ansi-red-fg\">KeyError</span>: \"None of [Index(['???'], dtype='object')] are in the [columns]\"</pre>\n```\n:::\n\n:::\n:::\n\n\nWhat is the model's mean squared error ($MSE$) and the coefficient of determination ($R^2$) ?\n\n::: {#cell-27 .cell execution_count=14}\n``` {.python .cell-code}\nfrom sklearn import metrics\n\n# Analysis for all months together.\nx = wdi[['???']]\ny = wdi[['???']]\nmodel = LinearRegression()\nmodel.fit(x, y)\ny_hat = model.predict(x)\nplt.plot(x, y,'o', alpha = 0.5)\nplt.plot(x, y_hat, 'r', alpha = 0.5)\nplt.xlabel('?')\nplt.ylabel('?')\nprint (\"MSE:\", metrics.mean_squared_error(y_hat, y))\nprint (\"R^2:\", metrics.r2_score(y_hat, y))\nprint (\"var:\", y.var())\nplt.savefig(\"?.png\", dpi = 300, bbox_inches = 'tight')\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[8], line 4</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span> <span style=\"font-weight:bold;color:rgb(0,0,255)\">sklearn</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> metrics\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Analysis for all months together.</span>\n<span class=\"ansi-green-fg\">----&gt; 4</span> x <span style=\"color:rgb(98,98,98)\">=</span> <span class=\"ansi-yellow-bg\">wdi</span>[[<span style=\"color:rgb(175,0,0)\">'</span><span style=\"color:rgb(175,0,0)\">???</span><span style=\"color:rgb(175,0,0)\">'</span>]]\n<span class=\"ansi-green-fg ansi-bold\">      5</span> y <span style=\"color:rgb(98,98,98)\">=</span> wdi[[<span style=\"color:rgb(175,0,0)\">'</span><span style=\"color:rgb(175,0,0)\">???</span><span style=\"color:rgb(175,0,0)\">'</span>]]\n<span class=\"ansi-green-fg ansi-bold\">      6</span> model <span style=\"color:rgb(98,98,98)\">=</span> LinearRegression()\n\n<span class=\"ansi-red-fg\">NameError</span>: name 'wdi' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\nWhat's the conclusion?\n\n\n",
    "supporting": [
      "IM939_Lab_3_Exercise_Linear_Regression_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}